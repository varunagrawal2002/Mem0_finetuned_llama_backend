{
  "input_file": "benchmark_test_retreivel_quality.jsonl",
  "summary": {
    "total_queries": 100,
    "successful_queries": 100,
    "failed_queries": 0,
    "hits_at_1": 18,
    "hits_at_3": 23,
    "hits_at_5": 24,
    "recall_at_1_pct": 18.0,
    "recall_at_3_pct": 23.0,
    "recall_at_5_pct": 24.0,
    "precision_at_5_pct": 4.8,
    "mean_reciprocal_rank": 0.2037
  },
  "detailed_results": [
    {
      "query_num": 1,
      "query": "What was the main outcome of the Q3 Nexus team meeting?",
      "expected_id": "mem_20",
      "expected_memory": "During the Q3 planning meeting, the 'Nexus' team committed to refactoring the entire authentication service. This is a high-priority task because the current system has major security vulnerabilities. The estimated completion date is October 15th.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4087141780868949,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.38278416713438684,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.38061499066313453,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.3784784995619219,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Logitech MX Master 3 mouse",
          "memory_id": "81bea507-6bde-41fe-bf57-8fdd4d8409f9",
          "ground_truth_id": "mem_68",
          "score": 0.37204859666667855,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_98",
        "mem_112",
        "mem_119",
        "mem_99",
        "mem_68"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 2,
      "query": "What do I need to do before my December vacation?",
      "expected_id": "mem_21",
      "expected_memory": "My manager, David Lee, approved my vacation request for December 20th to January 2nd. He specifically asked me to ensure all my active projects are handed over to Sarah Jenkins before I leave.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Eating window is 12-8 pm",
          "memory_id": "a94b8527-dbe5-4741-80ce-ad7989edc620",
          "ground_truth_id": "mem_90",
          "score": 0.4803586023813058,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.4716897791369668,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4487670050602429,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.43842748743235016,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "book a flight to New Orleans",
          "memory_id": "7784356a-025e-4e4d-9166-ce6285cf0b7b",
          "ground_truth_id": "mem_94",
          "score": 0.42610396963349123,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_90",
        "mem_98",
        "mem_98",
        "mem_94",
        "mem_94"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 3,
      "query": "What was the key lesson from the Atlas project failure?",
      "expected_id": "mem_22",
      "expected_memory": "The 'Atlas' project post-mortem revealed that our biggest bottleneck was the QA environment setup. It took three weeks longer than planned. We agreed to invest in infrastructure-as-code (IaC) using Terraform to prevent this in the future.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.4276618516673407,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.42734370104217245,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.42062560895648315,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "loved the movie 'Blade Runner 2049'",
          "memory_id": "e7faf6d3-0787-4af7-a8de-d164e6b59dc5",
          "ground_truth_id": "mem_45",
          "score": 0.37982299022724875,
          "metadata": {
            "ground_truth_id": "mem_45"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.3757626818937302,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_107",
        "mem_99",
        "mem_97",
        "mem_45",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 4,
      "query": "Who are my key contacts for the Orion project?",
      "expected_id": "mem_23",
      "expected_memory": "I've been assigned as the new technical lead for the 'Orion' integration. My main contacts will be Jane Doe from the partner company (jane.doe@partner.com) and our internal stakeholder, Mark Chen.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.4918181707636273,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.4557300527760867,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.45130971129963465,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.4423081440042587,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "with Docker",
          "memory_id": "3147db4b-4b9d-4c9b-af37-b2cea58be2ab",
          "ground_truth_id": "mem_113",
          "score": 0.4423081440042587,
          "metadata": {
            "ground_truth_id": "mem_113"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_97",
        "mem_89",
        "mem_98",
        "mem_55",
        "mem_113"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 5,
      "query": "What was the user feedback from the last sprint?",
      "expected_id": "mem_24",
      "expected_memory": "Feedback from the last sprint review was mixed. Users loved the new dashboard UI but complained that the data-loading speed is unacceptably slow, especially on the 'Analytics' page. We need to prioritize backend optimization.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.45278361408989914,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Ticketmaster",
          "memory_id": "470fd441-e9cc-4d7a-bea8-b501cd167f16",
          "ground_truth_id": "mem_93",
          "score": 0.4249020836970516,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.42465519259209683,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "7676e80e-02c3-4041-8911-c188e6b96d36",
          "ground_truth_id": "mem_90",
          "score": 0.42465519259209683,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.42465519259209683,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_89",
        "mem_93",
        "mem_68",
        "mem_90",
        "mem_117"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 6,
      "query": "When does my on-call duty start and who is my backup?",
      "expected_id": "mem_25",
      "expected_memory": "Our team's new on-call rotation starts next Monday. I am the primary contact for the first week (Week 1). Alex will be my secondary (backup). The emergency hotline number is 555-1234.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.5191724655630623,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.5062798578187149,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.46942929147963913,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "at the local animal shelter this Saturday from 9 AM to 12 PM",
          "memory_id": "988bf693-6fe4-4cef-a8e5-441cb9a76b3c",
          "ground_truth_id": "mem_98",
          "score": 0.45082270810147873,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.44926785918106055,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_89",
        "mem_98",
        "mem_99",
        "mem_98",
        "mem_94"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 7,
      "query": "What's the new policy for using open-source libraries on Project Titan?",
      "expected_id": "mem_26",
      "expected_memory": "The legal department just sent a memo that all new open-source libraries must be approved by the security team. This applies to 'Project Titan' immediately. I need to submit 'D3.js' and 'pandas' for review.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "with Docker",
          "memory_id": "3147db4b-4b9d-4c9b-af37-b2cea58be2ab",
          "ground_truth_id": "mem_113",
          "score": 0.5067709999002561,
          "metadata": {
            "ground_truth_id": "mem_113"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.5067709999002561,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.45061764814646793,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.4337209039447183,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.39643101219043503,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_113",
        "mem_55",
        "mem_107",
        "mem_97",
        "mem_112"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 8,
      "query": "What are my professional goals right now?",
      "expected_id": "mem_27",
      "expected_memory": "My performance goals for this quarter are: 1) Increase API endpoint performance by 15%, and 2) Mentor the new junior developer, Kevin. My stretch goal is to complete the AWS Solutions Architect certification.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.6558885984212208,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.503621043548949,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4797723633369042,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "courses",
          "memory_id": "5f098a6e-ae52-47cb-9017-e2396f124753",
          "ground_truth_id": "mem_118",
          "score": 0.4586913574339277,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.4097506672127281,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_99",
        "mem_98",
        "mem_98",
        "mem_118",
        "mem_107"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 9,
      "query": "What's the major complaint from the GlobalCorp client?",
      "expected_id": "mem_28",
      "expected_memory": "Client 'GlobalCorp' is very unhappy with our reporting module. They claim the data is 'frequently stale' by at least 24 hours. We need to investigate our data pipeline's refresh rate.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.48716236689686376,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.45372354309822666,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.45231079422666265,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.4410712380490176,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Ticketmaster",
          "memory_id": "470fd441-e9cc-4d7a-bea8-b501cd167f16",
          "ground_truth_id": "mem_93",
          "score": 0.4290681977938813,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_95",
        "mem_112",
        "mem_89",
        "mem_54",
        "mem_93"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 10,
      "query": "What was my main contribution to the 'FreshStart' campaign idea?",
      "expected_id": "mem_29",
      "expected_memory": "I had a brainstorming session for the new marketing campaign, 'FreshStart'. My best idea was a user-generated content contest on Instagram. The team seemed to like it, and we're mocking up a proposal.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.5622274030550378,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.5260845697287535,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.5187851986554506,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.4466949135235931,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.4324662048963059,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_98",
        "mem_99",
        "mem_98",
        "mem_107",
        "mem_99"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 11,
      "query": "What allergies does Emily have?",
      "expected_id": "mem_30",
      "expected_memory": "My sister, Emily, is allergic to peanuts and shellfish. Her birthday is next month, and I was thinking of baking her a cake, so I must use almond flour and sunflower seed butter instead.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "allergic to Tide",
          "memory_id": "8ad7a386-d2ac-4c41-8a25-834b8a1092c0",
          "ground_truth_id": "mem_115",
          "score": 0.6186432524780047,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "has a rash on his arm",
          "memory_id": "39faa81f-c051-4aef-9fed-935fe761f976",
          "ground_truth_id": "mem_115",
          "score": 0.5026134456261009,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.46060449743329457,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.42051156575384946,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.38556874461159973,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_115",
        "mem_115",
        "mem_99",
        "mem_119",
        "mem_95"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 12,
      "query": "What's my car insurance policy number?",
      "expected_id": "mem_31",
      "expected_memory": "I just renewed my car insurance with 'AutoSafe'. The policy number is #POL-987654. The renewal date is November 1st, 2026, and I'm paying $120 per month.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Modifying my car",
          "memory_id": "0875505b-b3bd-47c3-8f23-b5605031f3a5",
          "ground_truth_id": "mem_109",
          "score": 0.4392040035613758,
          "metadata": {
            "ground_truth_id": "mem_109"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "selling old car",
          "memory_id": "cc55a3cf-a7fc-4e30-9cc1-14fdbdd9e06b",
          "ground_truth_id": "mem_87",
          "score": 0.43832908054032105,
          "metadata": {
            "ground_truth_id": "mem_87"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.429615923092664,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.4276405814371143,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.42474087190560783,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_109",
        "mem_87",
        "mem_89",
        "mem_112",
        "mem_89"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 13,
      "query": "What am I responsible for at dad's birthday party?",
      "expected_id": "mem_32",
      "expected_memory": "My father's 60th birthday party is on Saturday, September 10th, at 6 PM at The Oak Room. I'm in charge of bringing the projector for the photo slideshow.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.5763632737343849,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.47690224400556314,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.46239718459661305,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.43928200922437455,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "neighbor's name is Tom",
          "memory_id": "c4e48c49-4af9-4cf5-a9c8-07794c5f15e1",
          "ground_truth_id": "mem_119",
          "score": 0.43011215917811146,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_94",
        "mem_98",
        "mem_98",
        "mem_112",
        "mem_119"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 14,
      "query": "What are the care instructions for my new dog, Buddy?",
      "expected_id": "mem_33",
      "expected_memory": "We just adopted a rescue dog, a golden retriever mix named 'Buddy'. The vet said he needs to be on a grain-free diet and needs his heartworm medication on the 1st of every month.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "dog walking",
          "memory_id": "368e506e-875c-4204-b5cb-0cbbab536909",
          "ground_truth_id": "mem_98",
          "score": 0.5479704110200968,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "at the local animal shelter this Saturday from 9 AM to 12 PM",
          "memory_id": "988bf693-6fe4-4cef-a8e5-441cb9a76b3c",
          "ground_truth_id": "mem_98",
          "score": 0.5455181768868659,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.5184610044152727,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.4553499948733484,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "neighbor's name is Tom",
          "memory_id": "c4e48c49-4af9-4cf5-a9c8-07794c5f15e1",
          "ground_truth_id": "mem_119",
          "score": 0.45421442121832817,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_98",
        "mem_98",
        "mem_98",
        "mem_112",
        "mem_119"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 15,
      "query": "What's our savings plan for the house?",
      "expected_id": "mem_34",
      "expected_memory": "My partner and I are saving for a house down payment. We agreed to set aside $1,500 each month into our joint savings account (ending in ...5678). Our target is $80,000.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.5205351148280006,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.4836799446292329,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.4575024513698011,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.445273405960267,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.4111800804822663,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_112",
        "mem_119",
        "mem_89",
        "mem_89",
        "mem_94"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 16,
      "query": "How did I fix the leaky faucet?",
      "expected_id": "mem_35",
      "expected_memory": "I finally fixed the leaky faucet in the upstairs bathroom. The problem was a worn-out O-ring in the hot water handle. I bought a 10-pack of replacements (size 'A-12') at Home Depot.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.4265422837915491,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Modifying my car",
          "memory_id": "0875505b-b3bd-47c3-8f23-b5605031f3a5",
          "ground_truth_id": "mem_109",
          "score": 0.4033582440434207,
          "metadata": {
            "ground_truth_id": "mem_109"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.38866291832336375,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.36788351026974997,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "-2.50 in the right eye",
          "memory_id": "c7376043-6858-4a41-a398-4d7ca54a46ef",
          "ground_truth_id": "mem_81",
          "score": 0.3596945646329367,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_112",
        "mem_109",
        "mem_54",
        "mem_99",
        "mem_81"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 17,
      "query": "How do I pay my rent?",
      "expected_id": "mem_36",
      "expected_memory": "My new landlord's name is Mr. Henderson, and his phone number is 555-9876. Rent is due on the 1st, and he prefers payment via Zelle to his email: 'henderson.rentals@email.com'.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.7052216088685087,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.5709541423947941,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.48893573541892865,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.46123484158750294,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.4589523878536257,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_112",
        "mem_119",
        "mem_89",
        "mem_89",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 18,
      "query": "What are the plans for Sophie's recital?",
      "expected_id": "mem_37",
      "expected_memory": "My daughter, Sophie, has her piano recital on Friday at 7 PM. I promised her I would be in the front row and that we would go for ice cream afterward to celebrate.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.46257484719642605,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.45066788298564936,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "courses",
          "memory_id": "5f098a6e-ae52-47cb-9017-e2396f124753",
          "ground_truth_id": "mem_118",
          "score": 0.44640986097824864,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.44631590155170753,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.4448664138529389,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_94",
        "mem_98",
        "mem_118",
        "mem_98",
        "mem_119"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 19,
      "query": "What do I need to remember for my upcoming doctor's appointment?",
      "expected_id": "mem_38",
      "expected_memory": "My annual physical is scheduled with Dr. Patel on October 28th at 10:00 AM. They reminded me to fast for 12 hours beforehand for the blood work.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.45653798912212945,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Eating window is 12-8 pm",
          "memory_id": "a94b8527-dbe5-4741-80ce-ad7989edc620",
          "ground_truth_id": "mem_90",
          "score": 0.44915635267521825,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.44304266426724576,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.4294293973245177,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.423944385833085,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_94",
        "mem_90",
        "mem_98",
        "mem_95",
        "mem_99"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 20,
      "query": "Who was that financial advisor my uncle recommended?",
      "expected_id": "mem_39",
      "expected_memory": "My uncle Joe recommended a great financial advisor named Maria Torres. He said she specializes in retirement planning for tech employees. Her office is on 123 Main St.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.5624217074132185,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "neighbor's name is Tom",
          "memory_id": "c4e48c49-4af9-4cf5-a9c8-07794c5f15e1",
          "ground_truth_id": "mem_119",
          "score": 0.4487682591640353,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "book series recommended by friend",
          "memory_id": "dfd8a705-37e9-4f48-a3d6-75781c661b44",
          "ground_truth_id": "mem_97",
          "score": 0.4450562767239536,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.4324490626213333,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.416699085429068,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_99",
        "mem_119",
        "mem_97",
        "mem_89",
        "mem_89"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 21,
      "query": "What am I thinking about the book I'm reading?",
      "expected_id": "mem_40",
      "expected_memory": "I'm currently reading 'Dune' by Frank Herbert. I'm about halfway through and finding the political intrigue more interesting than the action. I need to remember to buy the sequel, 'Dune Messiah'.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "book series recommended by friend",
          "memory_id": "dfd8a705-37e9-4f48-a3d6-75781c661b44",
          "ground_truth_id": "mem_97",
          "score": 0.5359425627796786,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.4720986639645719,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.45952724352942786,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.4398441662688878,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4286468379164784,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_97",
        "mem_97",
        "mem_99",
        "mem_108",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 22,
      "query": "How am I trying to fix my sourdough starter?",
      "expected_id": "mem_41",
      "expected_memory": "My sourdough starter, which I named 'Doughbi-Wan', seems to be struggling. It's not rising as much. I'm going to try switching to a 100% rye flour feeding schedule (1:2:2 ratio) starting tomorrow.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Modifying my car",
          "memory_id": "0875505b-b3bd-47c3-8f23-b5605031f3a5",
          "ground_truth_id": "mem_109",
          "score": 0.4551994460162796,
          "metadata": {
            "ground_truth_id": "mem_109"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.45210634994150484,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.4317235917783795,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.3925157356924872,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.39227774749338884,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_109",
        "mem_107",
        "mem_112",
        "mem_98",
        "mem_54"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 23,
      "query": "What guitar chord am I struggling with?",
      "expected_id": "mem_42",
      "expected_memory": "I've been practicing the 'Wonderwall' chords on my guitar, but I'm having trouble with the F-major barre chord. My fingers keep muting the high E string. I should watch some YouTube tutorials on finger placement.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "trying to learn Japanese",
          "memory_id": "824d4664-6979-454e-9eb6-b1d6c229ef62",
          "ground_truth_id": "mem_46",
          "score": 0.43959160631420957,
          "metadata": {
            "ground_truth_id": "mem_46"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.3845432273446881,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Section B, Row 12",
          "memory_id": "ef1eaead-783b-463f-a8fb-af9a84d2570b",
          "ground_truth_id": "mem_93",
          "score": 0.3782356902803309,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.37008000296520505,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "-2.50 in the right eye",
          "memory_id": "c7376043-6858-4a41-a398-4d7ca54a46ef",
          "ground_truth_id": "mem_81",
          "score": 0.36995824752175077,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_46",
        "mem_110",
        "mem_93",
        "mem_110",
        "mem_81"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 24,
      "query": "What's my 5K running goal?",
      "expected_id": "mem_43",
      "expected_memory": "My best 5K running time is 24:30, which I set last April. I'm training for the upcoming 'Turkey Trot' race and my goal is to break 24 minutes. My current training plan involves interval runs on Tuesdays.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.4599531942679934,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.434181664658285,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "7676e80e-02c3-4041-8911-c188e6b96d36",
          "ground_truth_id": "mem_90",
          "score": 0.434181664658285,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.434181664658285,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.434181664658285,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_98",
        "mem_68",
        "mem_90",
        "mem_117",
        "mem_117"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 25,
      "query": "What are the specs for the new PC I'm building?",
      "expected_id": "mem_44",
      "expected_memory": "I'm building a new PC. I've decided on the 'NVIDIA RTX 5070' GPU and the 'AMD Ryzen 9 9900X' CPU. I'm still debating between 32GB and 64GB of DDR5 RAM.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.4638114819756324,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.42532309002672547,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Modifying my car",
          "memory_id": "0875505b-b3bd-47c3-8f23-b5605031f3a5",
          "ground_truth_id": "mem_109",
          "score": 0.4101098586704111,
          "metadata": {
            "ground_truth_id": "mem_109"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.3812172337139872,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.3812172337139872,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_110",
        "mem_107",
        "mem_109",
        "mem_117",
        "mem_117"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 26,
      "query": "What did I think of the Blade Runner sequel?",
      "expected_id": "mem_45",
      "expected_memory": "I loved the movie 'Blade Runner 2049'. The cinematography and world-building were incredible. I thought the score by Hans Zimmer was a masterpiece, perfectly capturing the film's tone.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "loved the movie 'Blade Runner 2049'",
          "memory_id": "e7faf6d3-0787-4af7-a8de-d164e6b59dc5",
          "ground_truth_id": "mem_45",
          "score": 0.7028154604032405,
          "metadata": {
            "ground_truth_id": "mem_45"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.4509088352746646,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.4352902380646015,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.41568994759807787,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "favorite 'comfort movie' is 'Spirited Away',",
          "memory_id": "a03da5c2-6fda-41af-8684-5c5fef44ad1d",
          "ground_truth_id": "mem_118",
          "score": 0.40105183014854107,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_45",
        "mem_108",
        "mem_99",
        "mem_99",
        "mem_118"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 27,
      "query": "What's the hardest part of learning Japanese for me?",
      "expected_id": "mem_46",
      "expected_memory": "I'm trying to learn Japanese using the Duolingo app. I'm finding the grammar particles 'wa' () and 'ga' () very confusing. I need to find a dedicated grammar guide to explain the difference.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "trying to learn Japanese",
          "memory_id": "824d4664-6979-454e-9eb6-b1d6c229ef62",
          "ground_truth_id": "mem_46",
          "score": 0.7867216039306808,
          "metadata": {
            "ground_truth_id": "mem_46"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4212141778061701,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.40427287470440076,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.3906553584493676,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.38255413795284504,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_46",
        "mem_98",
        "mem_107",
        "mem_108",
        "mem_95"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 28,
      "query": "Why am I canceling my 'CodeMonthly' subscription?",
      "expected_id": "mem_47",
      "expected_memory": "My subscription to 'CodeMonthly' magazine is expiring in January. I don't think I'll renew it because most of the articles are too basic. I'm thinking of subscribing to 'ACM Queue' instead.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.4493526423415381,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.43343787523764415,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.4291644649375838,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.4169542567951999,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.4169542567951999,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_89",
        "mem_89",
        "mem_95",
        "mem_117",
        "mem_117"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 29,
      "query": "How did I beat that really hard boss in Elden Ring?",
      "expected_id": "mem_48",
      "expected_memory": "I've been playing the game 'Elden Ring'. I finally beat the boss 'Malenia' after 3 days of trying. The key was using the 'Rivers of Blood' katana and dodging her 'Waterfowl Dance' attack.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.4018954530251012,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.3693055604935487,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.36564417659952564,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.3523355068926199,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "-2.75 in the left eye",
          "memory_id": "f518404d-b77f-4d94-8cd8-040fd4e782ba",
          "ground_truth_id": "mem_81",
          "score": 0.3464005023260599,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_112",
        "mem_108",
        "mem_95",
        "mem_99",
        "mem_81"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 30,
      "query": "What are my Yosemite trip details?",
      "expected_id": "mem_49",
      "expected_memory": "I'm planning a camping trip to Yosemite in July. I managed to book the 'Upper Pines' campground (Site #112). I must remember to buy a bear canister, as it's required.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Ticketmaster",
          "memory_id": "470fd441-e9cc-4d7a-bea8-b501cd167f16",
          "ground_truth_id": "mem_93",
          "score": 0.45761629091469214,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.45066727973390697,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "bought tickets to see The National",
          "memory_id": "1b16da6d-8d23-4e30-b586-c984fc0938e6",
          "ground_truth_id": "mem_93",
          "score": 0.4390211179202476,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "book a flight to New Orleans",
          "memory_id": "7784356a-025e-4e4d-9166-ce6285cf0b7b",
          "ground_truth_id": "mem_94",
          "score": 0.43167707975185243,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.4112447251546098,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_93",
        "mem_89",
        "mem_93",
        "mem_94",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 31,
      "query": "What's the difference between horizontal and vertical scaling?",
      "expected_id": "mem_50",
      "expected_memory": "I'm studying for my cloud certification and learned about the difference between 'horizontal scaling' (scaling out by adding more machines) and 'vertical scaling' (scaling up by adding more power, like CPU/RAM, to an existing machine).",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.4669362087938443,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "TCP is connection oriented",
          "memory_id": "5ad41dd3-0a6b-4da9-b1e0-a9aae94e1ded",
          "ground_truth_id": "mem_54",
          "score": 0.42362929293160423,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "-2.75 in the left eye",
          "memory_id": "f518404d-b77f-4d94-8cd8-040fd4e782ba",
          "ground_truth_id": "mem_81",
          "score": 0.4162777541148159,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "-2.50 in the right eye",
          "memory_id": "c7376043-6858-4a41-a398-4d7ca54a46ef",
          "ground_truth_id": "mem_81",
          "score": 0.40797529153283146,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.4022005050503494,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_107",
        "mem_54",
        "mem_81",
        "mem_81",
        "mem_110"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 32,
      "query": "What is RAG and how does it help LLMs?",
      "expected_id": "mem_51",
      "expected_memory": "I read an article about 'Retrieval-Augmented Generation' (RAG). It improves LLM accuracy by fetching external documents and adding them to the prompt as context, which helps reduce hallucinations.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "has a rash on his arm",
          "memory_id": "39faa81f-c051-4aef-9fed-935fe761f976",
          "ground_truth_id": "mem_115",
          "score": 0.4582435320345001,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.43857712964496254,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.43340513707216943,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.42744442197894705,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.42484434323383813,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_115",
        "mem_112",
        "mem_98",
        "mem_99",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 33,
      "query": "How can I optimize my slow Python script?",
      "expected_id": "mem_52",
      "expected_memory": "My Python script is running slowly. The profiler shows that 80% of the time is spent in a nested loop doing string concatenation. I should rewrite this to use a 'list.join()' method instead.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.4534944742986932,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.4534944742986932,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.4534944742986932,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "7676e80e-02c3-4041-8911-c188e6b96d36",
          "ground_truth_id": "mem_90",
          "score": 0.4534944742986932,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.4196562283935674,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_117",
        "mem_117",
        "mem_68",
        "mem_90",
        "mem_54"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 34,
      "query": "When should I avoid using 'git rebase'?",
      "expected_id": "mem_53",
      "expected_memory": "I learned the hard way that 'git rebase -i' is destructive and rewrites commit history. I should use 'git merge' instead when working on shared branches to avoid force-pushing and messing up my team's history.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "with Docker",
          "memory_id": "3147db4b-4b9d-4c9b-af37-b2cea58be2ab",
          "ground_truth_id": "mem_113",
          "score": 0.43790241521922885,
          "metadata": {
            "ground_truth_id": "mem_113"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.43790241521922885,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.403440640776873,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.40152010269921223,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.3982857975052104,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_113",
        "mem_55",
        "mem_107",
        "mem_98",
        "mem_99"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 35,
      "query": "What's the main difference between TCP and UDP?",
      "expected_id": "mem_54",
      "expected_memory": "The main difference between TCP and UDP is that TCP is connection-oriented and guarantees ordered delivery (like a phone call), while UDP is connectionless and does not (like sending a postcard). UDP is faster and used for things like video streaming.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "TCP is connection oriented",
          "memory_id": "5ad41dd3-0a6b-4da9-b1e0-a9aae94e1ded",
          "ground_truth_id": "mem_54",
          "score": 0.7134185340364783,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.6605043702920714,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.3940592928895196,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.38371856104450985,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.35188244114935774,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_54",
        "mem_54",
        "mem_110",
        "mem_95",
        "mem_112"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 36,
      "query": "What's important to remember when Dockerizing my Node app?",
      "expected_id": "mem_55",
      "expected_memory": "I'm trying to containerize my 'Node.js' app with 'Docker'. I need to make sure my '.dockerignore' file includes 'node_modules/' so I don't copy the local development modules into the image. The build should use 'npm ci' for a clean install.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "with Docker",
          "memory_id": "3147db4b-4b9d-4c9b-af37-b2cea58be2ab",
          "ground_truth_id": "mem_113",
          "score": 0.7162424979656171,
          "metadata": {
            "ground_truth_id": "mem_113"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.7162424979656171,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": true
        },
        {
          "rank": 3,
          "memory_text": "TCP is connection oriented",
          "memory_id": "5ad41dd3-0a6b-4da9-b1e0-a9aae94e1ded",
          "ground_truth_id": "mem_54",
          "score": 0.4550171008289662,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.4234689107341179,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.4196916717530099,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_113",
        "mem_55",
        "mem_54",
        "mem_107",
        "mem_112"
      ],
      "found_position": 2,
      "hit": true
    },
    {
      "query_num": 37,
      "query": "What's the difference between a LEFT JOIN and an INNER JOIN?",
      "expected_id": "mem_56",
      "expected_memory": "In SQL, a 'LEFT JOIN' will return all rows from the left table and the matched rows from the right table. If there is no match, the columns from the right table will be 'NULL'. An 'INNER JOIN' only returns rows where there is a match in *both* tables.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "TCP is connection oriented",
          "memory_id": "5ad41dd3-0a6b-4da9-b1e0-a9aae94e1ded",
          "ground_truth_id": "mem_54",
          "score": 0.4092308418863355,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.39955192356948954,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.39880622930905946,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "courses",
          "memory_id": "5f098a6e-ae52-47cb-9017-e2396f124753",
          "ground_truth_id": "mem_118",
          "score": 0.38575456697757704,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.37869620018360994,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_54",
        "mem_95",
        "mem_112",
        "mem_118",
        "mem_99"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 38,
      "query": "How can I manually trigger my GitHub Actions pipeline?",
      "expected_id": "mem_57",
      "expected_memory": "I'm setting up a new CI/CD pipeline in GitHub Actions. The 'workflow_dispatch' event trigger allows me to run the pipeline manually from the GitHub UI, which is useful for ad-hoc deployments.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "with Docker",
          "memory_id": "3147db4b-4b9d-4c9b-af37-b2cea58be2ab",
          "ground_truth_id": "mem_113",
          "score": 0.524363302572112,
          "metadata": {
            "ground_truth_id": "mem_113"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.524363302572112,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.44815756814614005,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.4312292885618215,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.4312292885618215,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_113",
        "mem_55",
        "mem_110",
        "mem_117",
        "mem_117"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 39,
      "query": "Can you explain async/await in JavaScript to me?",
      "expected_id": "mem_58",
      "expected_memory": "I finally understood how 'async/await' works in JavaScript. The 'await' keyword pauses the execution of an 'async' function until a 'Promise' is settled (either resolved or rejected). It makes asynchronous code look synchronous.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.47895156808331685,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "TCP is connection oriented",
          "memory_id": "5ad41dd3-0a6b-4da9-b1e0-a9aae94e1ded",
          "ground_truth_id": "mem_54",
          "score": 0.4639322443946448,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.40709241512950817,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Ticketmaster",
          "memory_id": "470fd441-e9cc-4d7a-bea8-b501cd167f16",
          "ground_truth_id": "mem_93",
          "score": 0.4057747327826776,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.39613063409635485,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_54",
        "mem_54",
        "mem_94",
        "mem_93",
        "mem_112"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 40,
      "query": "What's the advantage of GraphQL over REST?",
      "expected_id": "mem_59",
      "expected_memory": "A 'REST API' is an architectural style, whereas 'GraphQL' is a query language for APIs. With GraphQL, the client can request *exactly* the data it needs, which can prevent over-fetching or under-fetching of data common with REST.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "TCP is connection oriented",
          "memory_id": "5ad41dd3-0a6b-4da9-b1e0-a9aae94e1ded",
          "ground_truth_id": "mem_54",
          "score": 0.4156660028826201,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "with Docker",
          "memory_id": "3147db4b-4b9d-4c9b-af37-b2cea58be2ab",
          "ground_truth_id": "mem_113",
          "score": 0.4142676518545301,
          "metadata": {
            "ground_truth_id": "mem_113"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.4142676518545301,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.4010037501601367,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.39401111695730595,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_54",
        "mem_113",
        "mem_55",
        "mem_110",
        "mem_94"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 41,
      "query": "Why don't I like the new Android update?",
      "expected_id": "mem_60",
      "expected_memory": "I'm not a fan of the new 'Material You' design update on my Android phone. The colors are too pastel, and the widgets are oversized. I much preferred the cleaner look of Android 11.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.3914008780142232,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "allergic to Tide",
          "memory_id": "8ad7a386-d2ac-4c41-8a25-834b8a1092c0",
          "ground_truth_id": "mem_115",
          "score": 0.3705805952232648,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "7676e80e-02c3-4041-8911-c188e6b96d36",
          "ground_truth_id": "mem_90",
          "score": 0.36828882151743536,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.36828882151743536,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.36828882151743536,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_110",
        "mem_115",
        "mem_90",
        "mem_117",
        "mem_117"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 42,
      "query": "Why is 'The Daily Grind' my favorite cafe?",
      "expected_id": "mem_61",
      "expected_memory": "My favorite coffee shop is 'The Daily Grind'. They have the best cold brew, and the baristas are always friendly. It's also one of the few places with comfortable seating and reliable, fast WiFi.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.5640113312246211,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Eating window is 12-8 pm",
          "memory_id": "a94b8527-dbe5-4741-80ce-ad7989edc620",
          "ground_truth_id": "mem_90",
          "score": 0.5160893117375557,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.4620891353830781,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "loved the movie 'Blade Runner 2049'",
          "memory_id": "e7faf6d3-0787-4af7-a8de-d164e6b59dc5",
          "ground_truth_id": "mem_45",
          "score": 0.4370875363155633,
          "metadata": {
            "ground_truth_id": "mem_45"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "favorite 'comfort movie' is 'Spirited Away',",
          "memory_id": "a03da5c2-6fda-41af-8684-5c5fef44ad1d",
          "ground_truth_id": "mem_118",
          "score": 0.4298910353319261,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_99",
        "mem_90",
        "mem_108",
        "mem_45",
        "mem_118"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 43,
      "query": "Why do I prefer Vim over Emacs?",
      "expected_id": "mem_62",
      "expected_memory": "I've decided I'm a 'Vim' person, not an 'Emacs' person. I find Vim's modal editing to be much more efficient for coding once I got past the steep learning curve. The keybindings feel more natural.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.5036449557127152,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "7676e80e-02c3-4041-8911-c188e6b96d36",
          "ground_truth_id": "mem_90",
          "score": 0.45978904061207726,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.45978904061207726,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.45978904061207726,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.45978904061207726,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_110",
        "mem_90",
        "mem_68",
        "mem_117",
        "mem_117"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 44,
      "query": "What's my opinion on remote work?",
      "expected_id": "mem_63",
      "expected_memory": "I strongly believe that remote work is more productive for me. I can focus without office distractions, and I save two hours a day on commuting. I feel less stressed and get more deep work done.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.5333950298584983,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.45825975090286164,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "TCP is connection oriented",
          "memory_id": "5ad41dd3-0a6b-4da9-b1e0-a9aae94e1ded",
          "ground_truth_id": "mem_54",
          "score": 0.44642609296145136,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.4248602080802134,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.421309693499325,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_99",
        "mem_98",
        "mem_54",
        "mem_112",
        "mem_95"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 45,
      "query": "Why am I skipping Call of Duty this year?",
      "expected_id": "mem_64",
      "expected_memory": "I'm not going to buy the new 'Call of Duty' game this year. The last three installments have been too repetitive, and I'm tired of the 'battle royale' trend. I'm looking for a good single-player story-driven game instead.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.39839196412726985,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "bought tickets to see The National",
          "memory_id": "1b16da6d-8d23-4e30-b586-c984fc0938e6",
          "ground_truth_id": "mem_93",
          "score": 0.36927034515369994,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.3665424230284844,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "allergic to Tide",
          "memory_id": "8ad7a386-d2ac-4c41-8a25-834b8a1092c0",
          "ground_truth_id": "mem_115",
          "score": 0.3612950976953022,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Section B, Row 12",
          "memory_id": "ef1eaead-783b-463f-a8fb-af9a84d2570b",
          "ground_truth_id": "mem_93",
          "score": 0.3597974488457218,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_98",
        "mem_93",
        "mem_110",
        "mem_115",
        "mem_93"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 46,
      "query": "What's that history podcast I like so much?",
      "expected_id": "mem_65",
      "expected_memory": "My favorite podcast is 'Hardcore History'. I love the host's long-form, detailed storytelling. The episode on the 'Mongol Empire' was particularly fascinating and gave me a new perspective.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "book series recommended by friend",
          "memory_id": "dfd8a705-37e9-4f48-a3d6-75781c661b44",
          "ground_truth_id": "mem_97",
          "score": 0.47354369711475786,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.46943496880197855,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.45748706496400887,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.4025825602628404,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "courses",
          "memory_id": "5f098a6e-ae52-47cb-9017-e2396f124753",
          "ground_truth_id": "mem_118",
          "score": 0.38938156651785955,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_97",
        "mem_97",
        "mem_108",
        "mem_99",
        "mem_118"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 47,
      "query": "Why do I prefer Vue to React?",
      "expected_id": "mem_66",
      "expected_memory": "I've tried both 'React' and 'Vue' for frontend development. I prefer 'Vue' because of its simpler API, better documentation, and the way it cleanly separates HTML, CSS, and JS in single-file components.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.45014206567396164,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.4395654072954297,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.3981316086547716,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.3670129281774109,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "7676e80e-02c3-4041-8911-c188e6b96d36",
          "ground_truth_id": "mem_90",
          "score": 0.3647051678162577,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_110",
        "mem_110",
        "mem_107",
        "mem_108",
        "mem_90"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 48,
      "query": "What's my unpopular opinion about 'The Office'?",
      "expected_id": "mem_67",
      "expected_memory": "I think 'The Office (US)' is overrated. While I appreciate the humor, I find the 'cringe' comedy style to be too uncomfortable to watch most of the time. I much prefer the witty, fast-paced dialogue of 'Parks and Recreation'.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.4779267785470214,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.41798052027909804,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.3971758523418227,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.3611330752411325,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.35343660654253617,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_95",
        "mem_98",
        "mem_99",
        "mem_112",
        "mem_97"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 49,
      "query": "What do I think of my new mouse?",
      "expected_id": "mem_68",
      "expected_memory": "My 'Logitech MX Master 3' mouse is the best piece of tech I've bought all year. The ergonomic design is perfect, and the 'MagSpeed' scroll wheel is a game-changer for long documents and code.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Logitech MX Master 3 mouse",
          "memory_id": "81bea507-6bde-41fe-bf57-8fdd4d8409f9",
          "ground_truth_id": "mem_68",
          "score": 0.6582841480041249,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.5881379011385666,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.5881379011385666,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.5881379011385666,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "7676e80e-02c3-4041-8911-c188e6b96d36",
          "ground_truth_id": "mem_90",
          "score": 0.5881379011385666,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_68",
        "mem_117",
        "mem_117",
        "mem_68",
        "mem_90"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 50,
      "query": "When is my most productive time of day?",
      "expected_id": "mem_69",
      "expected_memory": "I find I'm most creative and productive in the early morning, from about 6 AM to 9 AM. After lunch, my energy dips significantly, and I'm better off doing administrative tasks or answering emails.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Eating window is 12-8 pm",
          "memory_id": "a94b8527-dbe5-4741-80ce-ad7989edc620",
          "ground_truth_id": "mem_90",
          "score": 0.5569003611590921,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.4699186857397071,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.457272303822774,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4466838013362984,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "at the local animal shelter this Saturday from 9 AM to 12 PM",
          "memory_id": "988bf693-6fe4-4cef-a8e5-441cb9a76b3c",
          "ground_truth_id": "mem_98",
          "score": 0.44562373049127346,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_90",
        "mem_98",
        "mem_99",
        "mem_98",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 51,
      "query": "What's the status of that critical payment bug?",
      "expected_id": "mem_70",
      "expected_memory": "Found a critical bug (T-982) in the payment module. It's a race condition that happens when two users check out simultaneously. The current workaround is to add a distributed lock using Redis. Mark's team is on it.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.5047591041717977,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Ticketmaster",
          "memory_id": "470fd441-e9cc-4d7a-bea8-b501cd167f16",
          "ground_truth_id": "mem_93",
          "score": 0.44169242662142927,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.4292202036818299,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.4244882089873988,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "has a rash on his arm",
          "memory_id": "39faa81f-c051-4aef-9fed-935fe761f976",
          "ground_truth_id": "mem_115",
          "score": 0.40695360214361825,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_54",
        "mem_93",
        "mem_89",
        "mem_89",
        "mem_115"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 52,
      "query": "What was the result of the Innovate Inc. renewal?",
      "expected_id": "mem_71",
      "expected_memory": "Client 'Innovate Inc.' just signed the 12-month contract renewal for $250k. They are very happy with the platform's stability but have requested a new feature: a dedicated 'admin audit log' for compliance. This is now a top priority for Q1.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.4480774718713667,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.43216390331626825,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.3915800711429255,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.3913294887089735,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.38831346780615444,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_89",
        "mem_112",
        "mem_89",
        "mem_99",
        "mem_97"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 53,
      "query": "How did Priya Sharma's interview go?",
      "expected_id": "mem_72",
      "expected_memory": "The candidate, 'Priya Sharma', was excellent in the technical interview. She aced the system design question on scaling a 'tiny URL' service. We should definitely move her to the final round with the VP. Her salary expectation is $140k.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.49695040228522047,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.470613605374648,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.3973657483628601,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.39302827525592215,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "loved the movie 'Blade Runner 2049'",
          "memory_id": "e7faf6d3-0787-4af7-a8de-d164e6b59dc5",
          "ground_truth_id": "mem_45",
          "score": 0.37723055329989913,
          "metadata": {
            "ground_truth_id": "mem_45"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_99",
        "mem_99",
        "mem_98",
        "mem_95",
        "mem_45"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 54,
      "query": "Why did our AWS bill go up and how do we fix it?",
      "expected_id": "mem_73",
      "expected_memory": "Our cloud costs on AWS went up 20% last month. The cost explorer shows the 'S3-Standard' storage class is the main culprit. We need to implement a lifecycle policy to move old data to 'Glacier Deep Archive'.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.49391562870479866,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.44227925382642524,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "allergic to Tide",
          "memory_id": "8ad7a386-d2ac-4c41-8a25-834b8a1092c0",
          "ground_truth_id": "mem_115",
          "score": 0.41443480895958723,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.40345491176828024,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.40119608478856517,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_89",
        "mem_112",
        "mem_115",
        "mem_54",
        "mem_55"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 55,
      "query": "What's the new company hybrid model?",
      "expected_id": "mem_74",
      "expected_memory": "The company's new WFH (Work From Home) policy for 2026 is a 3-2 hybrid model. Three days in the office (Mon, Tue, Thu) and two days remote. This is mandatory for all departments starting Feb 1st.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.4231422900755612,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.4168542806932658,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4161452978178365,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.41425031459534734,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.403284769644357,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_110",
        "mem_99",
        "mem_98",
        "mem_89",
        "mem_112"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 56,
      "query": "What did ZenDesk just launch?",
      "expected_id": "mem_75",
      "expected_memory": "Our main competitor, 'ZenDesk', just launched an AI-powered 'Instant Reply' feature. Our product team feels this is a major threat. We are fast-tracking our own 'Project Assist' to counter it.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "with Docker",
          "memory_id": "3147db4b-4b9d-4c9b-af37-b2cea58be2ab",
          "ground_truth_id": "mem_113",
          "score": 0.4579930326370206,
          "metadata": {
            "ground_truth_id": "mem_113"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.4579930326370206,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.43875369303355216,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.43875369303355216,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.43875369303355216,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_113",
        "mem_55",
        "mem_68",
        "mem_117",
        "mem_117"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 57,
      "query": "What's my upcoming presentation about?",
      "expected_id": "mem_76",
      "expected_memory": "I'm giving a presentation at the all-hands meeting next week. The topic is 'The Future of WebAssembly'. I need to finish my slides, especially the one on the 'WASI' (WebAssembly System Interface).",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.5254450886404499,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.4902478942086902,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "courses",
          "memory_id": "5f098a6e-ae52-47cb-9017-e2396f124753",
          "ground_truth_id": "mem_118",
          "score": 0.4879940793382889,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.465053502141314,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.4571701131482408,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_98",
        "mem_99",
        "mem_118",
        "mem_94",
        "mem_95"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 58,
      "query": "When is the new office furniture arriving?",
      "expected_id": "mem_77",
      "expected_memory": "The vendor for our new office furniture, 'Steelcase', has confirmed delivery for December 3rd. However, they can't install the standing desks until December 5th due to staffing.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.502611350858935,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Section B, Row 12",
          "memory_id": "ef1eaead-783b-463f-a8fb-af9a84d2570b",
          "ground_truth_id": "mem_93",
          "score": 0.4687103931527712,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.4526529581450064,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.45197396033941983,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4414048018244827,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_110",
        "mem_93",
        "mem_119",
        "mem_112",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 59,
      "query": "What was my last 1-on-1 with Ben about?",
      "expected_id": "mem_78",
      "expected_memory": "I had a 1-on-1 with my direct report, Ben. He's feeling burnt out from the 'Atlas' project's long hours. I approved his request to take next Friday off and told him to block 'no-meeting' time in his calendar.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.5654490121817753,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.4903375171356213,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.4668758854371285,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "has a rash on his arm",
          "memory_id": "39faa81f-c051-4aef-9fed-935fe761f976",
          "ground_truth_id": "mem_115",
          "score": 0.4458226653702249,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4451513431215882,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_95",
        "mem_99",
        "mem_99",
        "mem_115",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 60,
      "query": "Why is our API latency bad and what's the fix?",
      "expected_id": "mem_79",
      "expected_memory": "Our API service level objective (SLO) for p95 latency is 500ms. We breached it three times last week, traced back to a slow database query. We need to add an index to the 'users_events' table on the 'timestamp' column.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.5920071491549208,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "TCP is connection oriented",
          "memory_id": "5ad41dd3-0a6b-4da9-b1e0-a9aae94e1ded",
          "ground_truth_id": "mem_54",
          "score": 0.5426083384282006,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.4597177791529431,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "with Docker",
          "memory_id": "3147db4b-4b9d-4c9b-af37-b2cea58be2ab",
          "ground_truth_id": "mem_113",
          "score": 0.4597177791529431,
          "metadata": {
            "ground_truth_id": "mem_113"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.43126150599447705,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_54",
        "mem_54",
        "mem_55",
        "mem_113",
        "mem_94"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 61,
      "query": "What was that large transfer I made recently?",
      "expected_id": "mem_80",
      "expected_memory": "I just moved $10,000 from my checking account into my Vanguard brokerage account (VTI). This is part of my long-term strategy to max out my ETF investments for the year. I should not touch this.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.5028921500482224,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.4705231324110368,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.44359798321907695,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.42935969798292006,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "selling old car",
          "memory_id": "cc55a3cf-a7fc-4e30-9cc1-14fdbdd9e06b",
          "ground_truth_id": "mem_87",
          "score": 0.4217790272651829,
          "metadata": {
            "ground_truth_id": "mem_87"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_89",
        "mem_89",
        "mem_54",
        "mem_112",
        "mem_87"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 62,
      "query": "What did the eye doctor tell me?",
      "expected_id": "mem_81",
      "expected_memory": "My new eye prescription from Dr. Ahn is -2.75 for the left eye and -2.50 for the right. She also noted signs of digital eye strain and recommended using blue-light filtering glasses and the 20-20-20 rule.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "-2.75 in the left eye",
          "memory_id": "f518404d-b77f-4d94-8cd8-040fd4e782ba",
          "ground_truth_id": "mem_81",
          "score": 0.6551511343131663,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "-2.50 in the right eye",
          "memory_id": "c7376043-6858-4a41-a398-4d7ca54a46ef",
          "ground_truth_id": "mem_81",
          "score": 0.6293609363258323,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.5160088537905172,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.44978698711476406,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "has a rash on his arm",
          "memory_id": "39faa81f-c051-4aef-9fed-935fe761f976",
          "ground_truth_id": "mem_115",
          "score": 0.43107566731729346,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_81",
        "mem_81",
        "mem_99",
        "mem_95",
        "mem_115"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 63,
      "query": "What's the status of my water damage insurance claim?",
      "expected_id": "mem_82",
      "expected_memory": "I filed a claim with 'Lemonade' insurance for the water damage in my kitchen. The claim number is #LM-45A8. The adjuster, Mike, is scheduled to come by this Wednesday at 2 PM.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.5019227742717767,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "allergic to Tide",
          "memory_id": "8ad7a386-d2ac-4c41-8a25-834b8a1092c0",
          "ground_truth_id": "mem_115",
          "score": 0.4484862935932128,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.42628210662297467,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.42039114439010916,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "neighbor's name is Tom",
          "memory_id": "c4e48c49-4af9-4cf5-a9c8-07794c5f15e1",
          "ground_truth_id": "mem_119",
          "score": 0.4159665849525429,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_112",
        "mem_115",
        "mem_54",
        "mem_95",
        "mem_119"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 64,
      "query": "What did my accountant say about my freelance taxes?",
      "expected_id": "mem_83",
      "expected_memory": "My accountant, Sarah, advised me that since I'm doing freelance work, I need to make quarterly estimated tax payments. The next deadline is January 15th. I should set aside at least 25% of my freelance income.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.5200459533561913,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.49094848663816953,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.48924047828294337,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.3974901144143428,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.3822718629933252,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_99",
        "mem_112",
        "mem_95",
        "mem_89",
        "mem_119"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 65,
      "query": "What's this new diet I'm trying?",
      "expected_id": "mem_84",
      "expected_memory": "I'm trying a new intermittent fasting schedule: 16:8. My eating window is from 12:00 PM (noon) to 8:00 PM. I'm doing this to try and improve my energy levels, not just for weight loss.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Eating window is 12-8 pm",
          "memory_id": "a94b8527-dbe5-4741-80ce-ad7989edc620",
          "ground_truth_id": "mem_90",
          "score": 0.5309336402872148,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.43257593373509506,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "allergic to Tide",
          "memory_id": "8ad7a386-d2ac-4c41-8a25-834b8a1092c0",
          "ground_truth_id": "mem_115",
          "score": 0.4322801052346197,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4208121838038287,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "trying to learn Japanese",
          "memory_id": "824d4664-6979-454e-9eb6-b1d6c229ef62",
          "ground_truth_id": "mem_46",
          "score": 0.4175207878321408,
          "metadata": {
            "ground_truth_id": "mem_46"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_90",
        "mem_99",
        "mem_115",
        "mem_98",
        "mem_46"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 66,
      "query": "What were the terms of my mortgage refinance?",
      "expected_id": "mem_85",
      "expected_memory": "I just refinanced my mortgage. The new rate is 4.75% fixed for 30 years with 'Better Mortgage'. This will lower my monthly payment by about $220. The closing costs were $4,500.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.522014862458597,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.49967383983403263,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.4681777760802798,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.41474666952519407,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.406366340259844,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_112",
        "mem_89",
        "mem_89",
        "mem_119",
        "mem_99"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 67,
      "query": "What were my recent blood test results?",
      "expected_id": "mem_86",
      "expected_memory": "My blood test results came back. My Vitamin D levels are low (22 ng/mL). Dr. Patel recommended I take a 2000 IU Vitamin D3 supplement daily, especially during the winter.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "has a rash on his arm",
          "memory_id": "39faa81f-c051-4aef-9fed-935fe761f976",
          "ground_truth_id": "mem_115",
          "score": 0.481951731456253,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "-2.75 in the left eye",
          "memory_id": "f518404d-b77f-4d94-8cd8-040fd4e782ba",
          "ground_truth_id": "mem_81",
          "score": 0.47732221366546596,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "-2.50 in the right eye",
          "memory_id": "c7376043-6858-4a41-a398-4d7ca54a46ef",
          "ground_truth_id": "mem_81",
          "score": 0.4453804445839264,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "allergic to Tide",
          "memory_id": "8ad7a386-d2ac-4c41-8a25-834b8a1092c0",
          "ground_truth_id": "mem_115",
          "score": 0.4442143363370654,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.42647466924392285,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_115",
        "mem_81",
        "mem_81",
        "mem_115",
        "mem_99"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 68,
      "query": "What are the details for the car I'm selling?",
      "expected_id": "mem_87",
      "expected_memory": "I'm selling my old 2018 Honda Civic. I listed it on AutoTrader for $16,500. The VIN is #1HGFK...789. It has 62,000 miles and a small scratch on the rear bumper.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "selling old car",
          "memory_id": "cc55a3cf-a7fc-4e30-9cc1-14fdbdd9e06b",
          "ground_truth_id": "mem_87",
          "score": 0.7612468851764675,
          "metadata": {
            "ground_truth_id": "mem_87"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "Modifying my car",
          "memory_id": "0875505b-b3bd-47c3-8f23-b5605031f3a5",
          "ground_truth_id": "mem_109",
          "score": 0.6095681967732332,
          "metadata": {
            "ground_truth_id": "mem_109"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.4084275887257695,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.40527519857160066,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "-2.75 in the left eye",
          "memory_id": "f518404d-b77f-4d94-8cd8-040fd4e782ba",
          "ground_truth_id": "mem_81",
          "score": 0.3850154655871463,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_87",
        "mem_109",
        "mem_89",
        "mem_112",
        "mem_81"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 69,
      "query": "What did the roof inspector say?",
      "expected_id": "mem_88",
      "expected_memory": "The roof inspector said the shingles on the south side are curling and are near the end of their 20-year life. He quoted us $8,000 for a replacement. He said we have about 1-2 years before it becomes a leak risk.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.48067868687666904,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.4791637221607405,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "neighbor's name is Tom",
          "memory_id": "c4e48c49-4af9-4cf5-a9c8-07794c5f15e1",
          "ground_truth_id": "mem_119",
          "score": 0.4745153735614882,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.47353397729349916,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.42066098256479856,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_99",
        "mem_112",
        "mem_119",
        "mem_95",
        "mem_119"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 70,
      "query": "Why did I get that new Chase credit card?",
      "expected_id": "mem_89",
      "expected_memory": "I just signed up for a new credit card, the 'Chase Sapphire Reserve', to get the travel points. The annual fee is $550, but it includes a $300 travel credit and Priority Pass lounge access. I need to spend $4,000 in 3 months to get the bonus.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.6746892003544224,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.45683918707627447,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.42503013945032386,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "bought tickets to see The National",
          "memory_id": "1b16da6d-8d23-4e30-b586-c984fc0938e6",
          "ground_truth_id": "mem_93",
          "score": 0.4130261854741957,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Ticketmaster",
          "memory_id": "470fd441-e9cc-4d7a-bea8-b501cd167f16",
          "ground_truth_id": "mem_93",
          "score": 0.41266097005894675,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_89",
        "mem_89",
        "mem_99",
        "mem_93",
        "mem_93"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 71,
      "query": "What are my Berlin trip details?",
      "expected_id": "mem_90",
      "expected_memory": "I've booked my flight to Berlin for the tech conference. I fly on Lufthansa (LH 456) on March 3rd, landing at 9:00 AM. My hotel is The 'InterContinental', and my confirmation number is #B-6789. I need to remember to pack a European power adapter.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "book a flight to New Orleans",
          "memory_id": "7784356a-025e-4e4d-9166-ce6285cf0b7b",
          "ground_truth_id": "mem_94",
          "score": 0.4878686649622512,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Ticketmaster",
          "memory_id": "470fd441-e9cc-4d7a-bea8-b501cd167f16",
          "ground_truth_id": "mem_93",
          "score": 0.48138456400926477,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "bought tickets to see The National",
          "memory_id": "1b16da6d-8d23-4e30-b586-c984fc0938e6",
          "ground_truth_id": "mem_93",
          "score": 0.47239361261311297,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.44281211347861105,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.4409712318190576,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_94",
        "mem_93",
        "mem_93",
        "mem_89",
        "mem_94"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 72,
      "query": "What was that deep conversation I had with Alex about?",
      "expected_id": "mem_91",
      "expected_memory": "I had a long talk with my friend Alex last night. He's thinking of quitting his job at the law firm to become a chef. He seems really passionate about it but is worried about the pay cut. I told him to make a solid business plan first.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.5902190873092954,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.5494449238514046,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.5027518021167998,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.5014746264502005,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "book series recommended by friend",
          "memory_id": "dfd8a705-37e9-4f48-a3d6-75781c661b44",
          "ground_truth_id": "mem_97",
          "score": 0.44561531397077236,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_95",
        "mem_99",
        "mem_99",
        "mem_98",
        "mem_97"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 73,
      "query": "What am I doing this weekend?",
      "expected_id": "mem_92",
      "expected_memory": "This weekend's plans: Saturday morning, I have a dentist appointment at 10 AM. On Saturday night, we have dinner reservations at 'Osteria' at 8 PM for Maria's birthday. Sunday is for laundry and relaxing.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "at the local animal shelter this Saturday from 9 AM to 12 PM",
          "memory_id": "988bf693-6fe4-4cef-a8e5-441cb9a76b3c",
          "ground_truth_id": "mem_98",
          "score": 0.5327699667841695,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "bought tickets to see The National",
          "memory_id": "1b16da6d-8d23-4e30-b586-c984fc0938e6",
          "ground_truth_id": "mem_93",
          "score": 0.5222736009805113,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.5180452443152957,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Eating window is 12-8 pm",
          "memory_id": "a94b8527-dbe5-4741-80ce-ad7989edc620",
          "ground_truth_id": "mem_90",
          "score": 0.4991031163301307,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Ticketmaster",
          "memory_id": "470fd441-e9cc-4d7a-bea8-b501cd167f16",
          "ground_truth_id": "mem_93",
          "score": 0.48116176584657383,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_98",
        "mem_93",
        "mem_98",
        "mem_90",
        "mem_93"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 74,
      "query": "When am I seeing 'The National'?",
      "expected_id": "mem_93",
      "expected_memory": "I bought tickets to see 'The National' in concert. The show is on May 17th at the 'Greek Theatre'. The seats are in Section B, Row 12. I bought them on Ticketmaster, and they are in my digital wallet.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "bought tickets to see The National",
          "memory_id": "1b16da6d-8d23-4e30-b586-c984fc0938e6",
          "ground_truth_id": "mem_93",
          "score": 0.7816312010092954,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "Ticketmaster",
          "memory_id": "470fd441-e9cc-4d7a-bea8-b501cd167f16",
          "ground_truth_id": "mem_93",
          "score": 0.46660118471441325,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Eating window is 12-8 pm",
          "memory_id": "a94b8527-dbe5-4741-80ce-ad7989edc620",
          "ground_truth_id": "mem_90",
          "score": 0.44947563836014437,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "at the local animal shelter this Saturday from 9 AM to 12 PM",
          "memory_id": "988bf693-6fe4-4cef-a8e5-441cb9a76b3c",
          "ground_truth_id": "mem_98",
          "score": 0.4409317916164514,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.4225532165364343,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_93",
        "mem_93",
        "mem_90",
        "mem_98",
        "mem_97"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 75,
      "query": "What are the details for Chloe's wedding?",
      "expected_id": "mem_94",
      "expected_memory": "My cousin Chloe is getting married in New Orleans in June. The wedding is at the 'Hotel Peter & Paul'. I need to RSVP by May 1st and book my flight soon. The dress code is 'Garden Party Cocktail'.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.5678318111437217,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.40914895713154786,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.40234776484694246,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.3964305030225677,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "book series recommended by friend",
          "memory_id": "dfd8a705-37e9-4f48-a3d6-75781c661b44",
          "ground_truth_id": "mem_97",
          "score": 0.39601751636630245,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_94",
        "mem_99",
        "mem_95",
        "mem_97",
        "mem_97"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 76,
      "query": "What was that new chore agreement we made?",
      "expected_id": "mem_95",
      "expected_memory": "I had an argument with my partner about the household chores. We agreed to a new system: I'm responsible for all the cooking and kitchen cleanup, and they are responsible for laundry and vacuuming. We'll split the bathroom cleaning.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.5291594783444715,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.48240132070742037,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.47803281828280836,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": true
        },
        {
          "rank": 4,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.4547615172216538,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.4509162882011655,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_112",
        "mem_98",
        "mem_95",
        "mem_119",
        "mem_98"
      ],
      "found_position": 3,
      "hit": true
    },
    {
      "query_num": 77,
      "query": "What do I need to do for game night on Friday?",
      "expected_id": "mem_96",
      "expected_memory": "I'm hosting a game night this Friday. So far, Chris, Megan, and Sam are coming. I need to buy snacks (chips, salsa, and pretzels) and pick up a new copy of 'Catan' because my old one is missing pieces.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Need to rsvp for wedding",
          "memory_id": "800a3653-e27b-4d7c-97ac-ad8bf8c10656",
          "ground_truth_id": "mem_94",
          "score": 0.4814884145098338,
          "metadata": {
            "ground_truth_id": "mem_94"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Eating window is 12-8 pm",
          "memory_id": "a94b8527-dbe5-4741-80ce-ad7989edc620",
          "ground_truth_id": "mem_90",
          "score": 0.4775133936453332,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.47747754896645,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Ticketmaster",
          "memory_id": "470fd441-e9cc-4d7a-bea8-b501cd167f16",
          "ground_truth_id": "mem_93",
          "score": 0.4737649572313437,
          "metadata": {
            "ground_truth_id": "mem_93"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "at the local animal shelter this Saturday from 9 AM to 12 PM",
          "memory_id": "988bf693-6fe4-4cef-a8e5-441cb9a76b3c",
          "ground_truth_id": "mem_98",
          "score": 0.47054849916024355,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_94",
        "mem_90",
        "mem_98",
        "mem_93",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 78,
      "query": "What was that book series Jen recommended?",
      "expected_id": "mem_97",
      "expected_memory": "My friend Jen recommended a new sci-fi book series, 'The Expanse'. She said it's a great mix of 'hard sci-fi' and 'political drama', and that the first book is called 'Leviathan Wakes'.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "book series recommended by friend",
          "memory_id": "dfd8a705-37e9-4f48-a3d6-75781c661b44",
          "ground_truth_id": "mem_97",
          "score": 0.8024659310590021,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.5795375907491142,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.4806381227374992,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.46486758359167313,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.4383979613181128,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_97",
        "mem_97",
        "mem_99",
        "mem_99",
        "mem_108"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 79,
      "query": "What are my volunteer duties at the shelter?",
      "expected_id": "mem_98",
      "expected_memory": "I'm volunteering at the local animal shelter this Saturday from 9 AM to 12 PM. My role is to help with 'dog walking' and 'socialization'. I need to remember to wear closed-toe shoes and old clothes.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.7387477022786885,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "at the local animal shelter this Saturday from 9 AM to 12 PM",
          "memory_id": "988bf693-6fe4-4cef-a8e5-441cb9a76b3c",
          "ground_truth_id": "mem_98",
          "score": 0.7069896140008343,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.46864771021582324,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.43544815218428834,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.42701641786691624,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_98",
        "mem_98",
        "mem_98",
        "mem_112",
        "mem_119"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 80,
      "query": "What career advice did Dr. Evans give me?",
      "expected_id": "mem_99",
      "expected_memory": "I had coffee with my old mentor, Dr. Evans. She gave me some great career advice: 'Don't just climb the ladder, build your own.' She thinks I should consider starting my own consulting side-business.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.8104752298488087,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.4465982125729148,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4291338597454307,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "courses",
          "memory_id": "5f098a6e-ae52-47cb-9017-e2396f124753",
          "ground_truth_id": "mem_118",
          "score": 0.4129565731216769,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.39398098967446993,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_99",
        "mem_98",
        "mem_98",
        "mem_118",
        "mem_95"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 81,
      "query": "What's the main concept I learned about Kubernetes?",
      "expected_id": "mem_100",
      "expected_memory": "I'm learning about Kubernetes. The core concept I finally grasp is the 'control plane' vs. 'data plane'. The control plane (with the API server, etcd) makes the decisions, and the data plane (kubelet, container runtime on nodes) does the actual work.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.5242082315052492,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "with Docker",
          "memory_id": "3147db4b-4b9d-4c9b-af37-b2cea58be2ab",
          "ground_truth_id": "mem_113",
          "score": 0.5242082315052492,
          "metadata": {
            "ground_truth_id": "mem_113"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "TCP is connection oriented",
          "memory_id": "5ad41dd3-0a6b-4da9-b1e0-a9aae94e1ded",
          "ground_truth_id": "mem_54",
          "score": 0.5220173446202097,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.4881067871702292,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4486170967280274,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_55",
        "mem_113",
        "mem_54",
        "mem_99",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 82,
      "query": "What was so special about that 'AlphaGo' documentary?",
      "expected_id": "mem_101",
      "expected_memory": "I watched a documentary on 'AlphaGo'. The most mind-blowing part was 'Move 37', where the AI made a completely novel and creative move that no human grandmaster would have considered. It showed AI can exhibit genuine creativity.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "loved the movie 'Blade Runner 2049'",
          "memory_id": "e7faf6d3-0787-4af7-a8de-d164e6b59dc5",
          "ground_truth_id": "mem_45",
          "score": 0.4362233072562223,
          "metadata": {
            "ground_truth_id": "mem_45"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "series name is The Expanse",
          "memory_id": "19733308-9c92-4311-a67e-fd6b92e02754",
          "ground_truth_id": "mem_97",
          "score": 0.39692689721213115,
          "metadata": {
            "ground_truth_id": "mem_97"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.37362303387706386,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.3679381747597186,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.36589130008485243,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_45",
        "mem_97",
        "mem_108",
        "mem_99",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 83,
      "query": "What's the secret to my new pizza dough recipe?",
      "expected_id": "mem_102",
      "expected_memory": "I'm trying to perfect my 'Neapolitan' pizza dough recipe. The key seems to be using '00' flour and a long, 72-hour cold fermentation in the fridge. This develops a much better flavor and crust structure.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Eating window is 12-8 pm",
          "memory_id": "a94b8527-dbe5-4741-80ce-ad7989edc620",
          "ground_truth_id": "mem_90",
          "score": 0.4383808954997199,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.42070497030232407,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.3919657491157559,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.38589225200862853,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.38282161444956825,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_90",
        "mem_107",
        "mem_119",
        "mem_98",
        "mem_112"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 84,
      "query": "What do I think of the new Cyberpunk update?",
      "expected_id": "mem_103",
      "expected_memory": "I've been playing the game 'Cyberpunk 2077' after the 2.0 update. It's so much better. The new 'perk' system completely changes the gameplay, and I'm doing a 'Netrunner' build focused on hacking.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.5270784846829895,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.4542431607696843,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.4509542502904871,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "loved the movie 'Blade Runner 2049'",
          "memory_id": "e7faf6d3-0787-4af7-a8de-d164e6b59dc5",
          "ground_truth_id": "mem_45",
          "score": 0.4508443799216653,
          "metadata": {
            "ground_truth_id": "mem_45"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "plays techno music at night",
          "memory_id": "2aaaa0e9-4558-4495-b0ab-a657a6ead300",
          "ground_truth_id": "mem_119",
          "score": 0.4388440481695927,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_108",
        "mem_110",
        "mem_107",
        "mem_45",
        "mem_119"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 85,
      "query": "What is the 'exposure triangle' in photography?",
      "expected_id": "mem_104",
      "expected_memory": "I'm practicing photography. I learned the 'exposure triangle': ISO (sensor sensitivity), Aperture (how much light gets in, controls depth of field), and Shutter Speed (how long the sensor is exposed, controls motion blur).",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "-2.75 in the left eye",
          "memory_id": "f518404d-b77f-4d94-8cd8-040fd4e782ba",
          "ground_truth_id": "mem_81",
          "score": 0.4487107015504448,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.4463728012821271,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "-2.50 in the right eye",
          "memory_id": "c7376043-6858-4a41-a398-4d7ca54a46ef",
          "ground_truth_id": "mem_81",
          "score": 0.4360882385409147,
          "metadata": {
            "ground_truth_id": "mem_81"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.421506067921009,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "7676e80e-02c3-4041-8911-c188e6b96d36",
          "ground_truth_id": "mem_90",
          "score": 0.421506067921009,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_81",
        "mem_107",
        "mem_81",
        "mem_68",
        "mem_90"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 86,
      "query": "What was my main takeaway from 'Atomic Habits'?",
      "expected_id": "mem_105",
      "expected_memory": "I just finished the book 'Atomic Habits' by James Clear. My biggest takeaway is the concept of 'identity-based habits'focusing on *who* you want to become, not just the *outcome* you want to achieve.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.5483691141308917,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.5190525785894392,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.497060839120891,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "loved the movie 'Blade Runner 2049'",
          "memory_id": "e7faf6d3-0787-4af7-a8de-d164e6b59dc5",
          "ground_truth_id": "mem_45",
          "score": 0.47325932783560964,
          "metadata": {
            "ground_truth_id": "mem_45"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.4407152142706626,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_99",
        "mem_98",
        "mem_99",
        "mem_45",
        "mem_119"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 87,
      "query": "What's frustrating me about my Lego build?",
      "expected_id": "mem_106",
      "expected_memory": "I'm building a new 'Lego' set, the 'Millennium Falcon' (Set #75192). It's incredibly detailed, but I'm stuck on 'Bag 12'. The instructions for the mandible framework are really confusing.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.5192346999130891,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "Modifying my car",
          "memory_id": "0875505b-b3bd-47c3-8f23-b5605031f3a5",
          "ground_truth_id": "mem_109",
          "score": 0.4438934877494125,
          "metadata": {
            "ground_truth_id": "mem_109"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.4402398933085455,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.43434465158131264,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.4284574339443804,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_107",
        "mem_109",
        "mem_110",
        "mem_110",
        "mem_95"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 88,
      "query": "What's the hardest part of learning Blender?",
      "expected_id": "mem_107",
      "expected_memory": "I've been learning to use 'Blender' for 3D modeling. The hardest part is understanding 'UV unwrapping'. It's the process of flattening the 3D model's surface into a 2D texture map, and it's very tedious.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.7635604003810519,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "trying to learn Japanese",
          "memory_id": "824d4664-6979-454e-9eb6-b1d6c229ef62",
          "ground_truth_id": "mem_46",
          "score": 0.4510038134954537,
          "metadata": {
            "ground_truth_id": "mem_46"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.42529642839271004,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.4111648987031263,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Modifying my car",
          "memory_id": "0875505b-b3bd-47c3-8f23-b5605031f3a5",
          "ground_truth_id": "mem_109",
          "score": 0.3941456399063172,
          "metadata": {
            "ground_truth_id": "mem_109"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_107",
        "mem_46",
        "mem_98",
        "mem_110",
        "mem_109"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 89,
      "query": "Why do I love 'Spirited Away' so much?",
      "expected_id": "mem_108",
      "expected_memory": "My favorite 'comfort movie' is 'Spirited Away'. I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi. It always makes me feel nostalgic and calm.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "favorite 'comfort movie' is 'Spirited Away',",
          "memory_id": "a03da5c2-6fda-41af-8684-5c5fef44ad1d",
          "ground_truth_id": "mem_118",
          "score": 0.7940321421060053,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "I love the art style, the magical world-building, and the soundtrack by Joe Hisaishi.",
          "memory_id": "32b05d3f-a48b-44bc-8088-a11acd65f913",
          "ground_truth_id": "mem_108",
          "score": 0.676132059049074,
          "metadata": {
            "ground_truth_id": "mem_108"
          },
          "is_correct": true
        },
        {
          "rank": 3,
          "memory_text": "loved the movie 'Blade Runner 2049'",
          "memory_id": "e7faf6d3-0787-4af7-a8de-d164e6b59dc5",
          "ground_truth_id": "mem_45",
          "score": 0.5399297553586373,
          "metadata": {
            "ground_truth_id": "mem_45"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.40640298806613734,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Had coffee with her",
          "memory_id": "caa0e844-3419-4750-8451-65f91da31329",
          "ground_truth_id": "mem_99",
          "score": 0.37193764446689104,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_118",
        "mem_108",
        "mem_45",
        "mem_98",
        "mem_99"
      ],
      "found_position": 2,
      "hit": true
    },
    {
      "query_num": 90,
      "query": "What modification did I just do to my car?",
      "expected_id": "mem_109",
      "expected_memory": "I'm modifying my 'Subaru WRX'. I just installed a 'Cobb Accessport' to flash a 'Stage 1' tune. It increases the boost and horsepower, but I have to make sure to only use 91 octane gas or higher from now on.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Modifying my car",
          "memory_id": "0875505b-b3bd-47c3-8f23-b5605031f3a5",
          "ground_truth_id": "mem_109",
          "score": 0.7963314416794286,
          "metadata": {
            "ground_truth_id": "mem_109"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "selling old car",
          "memory_id": "cc55a3cf-a7fc-4e30-9cc1-14fdbdd9e06b",
          "ground_truth_id": "mem_87",
          "score": 0.5043259081379672,
          "metadata": {
            "ground_truth_id": "mem_87"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.41322786494824737,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.41322786494824737,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.41322786494824737,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_109",
        "mem_87",
        "mem_68",
        "mem_117",
        "mem_117"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 91,
      "query": "What kind of keyboard switches do I like?",
      "expected_id": "mem_110",
      "expected_memory": "I've decided I strongly prefer mechanical keyboards with 'tactile' switches, not 'linear' or 'clicky' ones. The 'Cherry MX Brown' switch feels like the perfect balance of feedback and quietness for typing. 'Clicky' (Blue) switches are too loud.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.8052781662956221,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.7409466860992743,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.5704816737773034,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.5704816737773034,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.5704816737773034,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_110",
        "mem_110",
        "mem_117",
        "mem_117",
        "mem_68"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 92,
      "query": "What's that issue with my headphones?",
      "expected_id": "mem_111",
      "expected_memory": "The warranty on my 'Sony WH-1000XM5' headphones expires on January 15th, 2026. The left earcup has been making a slight rattling noise. I should probably get them checked before the warranty is up.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "plays techno music at night",
          "memory_id": "2aaaa0e9-4558-4495-b0ab-a657a6ead300",
          "ground_truth_id": "mem_119",
          "score": 0.4975168764461171,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.3879411188885443,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.38728823702062054,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "7676e80e-02c3-4041-8911-c188e6b96d36",
          "ground_truth_id": "mem_90",
          "score": 0.38728823702062054,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.38728823702062054,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_119",
        "mem_110",
        "mem_117",
        "mem_90",
        "mem_68"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 93,
      "query": "When is the AC getting fixed?",
      "expected_id": "mem_112",
      "expected_memory": "My apartment's AC unit is making a loud 'clanking' noise. I called the landlord, and they said a technician from 'Rapid Repair' will come on Friday between 1 PM and 4 PM. I have to be home to let them in.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.48285482730048435,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.46952359713716185,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Modifying my car",
          "memory_id": "0875505b-b3bd-47c3-8f23-b5605031f3a5",
          "ground_truth_id": "mem_109",
          "score": 0.44025269308711823,
          "metadata": {
            "ground_truth_id": "mem_109"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "UDP does not guarantee delivery",
          "memory_id": "ed3cb2b3-b820-4206-bc44-382795193757",
          "ground_truth_id": "mem_54",
          "score": 0.43652651152701066,
          "metadata": {
            "ground_truth_id": "mem_54"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "has a rash on his arm",
          "memory_id": "39faa81f-c051-4aef-9fed-935fe761f976",
          "ground_truth_id": "mem_115",
          "score": 0.41055427687852186,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_112",
        "mem_119",
        "mem_109",
        "mem_54",
        "mem_115"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 94,
      "query": "What was that app idea I had about plants?",
      "expected_id": "mem_113",
      "expected_memory": "I have an idea for a mobile app: 'PlantIQ'. It would use the phone's camera to identify a plant and then use the user's location to give hyper-specific watering and sunlight advice based on the local weather forecast.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Gave me career advice",
          "memory_id": "1dad9c2b-3ef5-41c6-9581-ad811c05bc78",
          "ground_truth_id": "mem_99",
          "score": 0.4562689980301986,
          "metadata": {
            "ground_truth_id": "mem_99"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "with Docker",
          "memory_id": "3147db4b-4b9d-4c9b-af37-b2cea58be2ab",
          "ground_truth_id": "mem_113",
          "score": 0.43873255799901467,
          "metadata": {
            "ground_truth_id": "mem_113"
          },
          "is_correct": true
        },
        {
          "rank": 3,
          "memory_text": "with Docker",
          "memory_id": "deaa9950-61a9-4a68-b68a-c18bd4891df6",
          "ground_truth_id": "mem_55",
          "score": 0.43873255799901467,
          "metadata": {
            "ground_truth_id": "mem_55"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.4350603088562895,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.4231949986082045,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_99",
        "mem_113",
        "mem_55",
        "mem_98",
        "mem_98"
      ],
      "found_position": 2,
      "hit": true
    },
    {
      "query_num": 95,
      "query": "What's my gym locker combo?",
      "expected_id": "mem_114",
      "expected_memory": "I keep forgetting my new gym locker combination. It's '38-12-24'. I should write this down in a secure note. 38 (right), 12 (left), 24 (right).",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.46774033790146,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "courses",
          "memory_id": "5f098a6e-ae52-47cb-9017-e2396f124753",
          "ground_truth_id": "mem_118",
          "score": 0.45523395466288147,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.4530876981107921,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "prefer mechanical keyboards",
          "memory_id": "38d5c764-481b-4d5d-bc17-e89469d899e9",
          "ground_truth_id": "mem_110",
          "score": 0.45288812036653014,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "Modifying my car",
          "memory_id": "0875505b-b3bd-47c3-8f23-b5605031f3a5",
          "ground_truth_id": "mem_109",
          "score": 0.4461338474103637,
          "metadata": {
            "ground_truth_id": "mem_109"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_119",
        "mem_118",
        "mem_89",
        "mem_110",
        "mem_109"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 96,
      "query": "Why do I have this rash on my arms?",
      "expected_id": "mem_115",
      "expected_memory": "I think I'm allergic to the new 'Tide' laundry detergent. I've been getting a rash on my arms. I'm going to switch back to 'All Free & Clear' and see if it goes away.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "has a rash on his arm",
          "memory_id": "39faa81f-c051-4aef-9fed-935fe761f976",
          "ground_truth_id": "mem_115",
          "score": 0.758653099612164,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "allergic to Tide",
          "memory_id": "8ad7a386-d2ac-4c41-8a25-834b8a1092c0",
          "ground_truth_id": "mem_115",
          "score": 0.5098175823457076,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "tactile switches",
          "memory_id": "592b8e96-bfb1-4e29-a0ec-2e6969a842b3",
          "ground_truth_id": "mem_110",
          "score": 0.372401213565589,
          "metadata": {
            "ground_truth_id": "mem_110"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.36137440748746463,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.3467839893918744,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_115",
        "mem_115",
        "mem_110",
        "mem_98",
        "mem_107"
      ],
      "found_position": 1,
      "hit": true
    },
    {
      "query_num": 97,
      "query": "What's the difference between 'Projects' and 'Areas' in my new filing system?",
      "expected_id": "mem_116",
      "expected_memory": "I'm trying to organize my digital files using the 'PARA' method (Projects, Areas, Resources, Archives). 'Projects' are for active work with a deadline, and 'Areas' are for ongoing responsibilities without a deadline, like 'Health' or 'Finances'.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "The user has been learning to use Blender for 3d modeling",
          "memory_id": "79ec10ff-4c93-4e15-b2b0-58391a92f82f",
          "ground_truth_id": "mem_107",
          "score": 0.4519733607766393,
          "metadata": {
            "ground_truth_id": "mem_107"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.4416858064797926,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.42207502266226593,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.4169382848521528,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.40927751562103243,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_107",
        "mem_112",
        "mem_95",
        "mem_119",
        "mem_98"
      ],
      "found_position": -1,
      "hit": false
    },
    {
      "query_num": 98,
      "query": "What's that fast, healthy recipe I like?",
      "expected_id": "mem_117",
      "expected_memory": "My favorite 'quick' weeknight dinner recipe is the 'NYT's' Curried Lentils with Coconut Milk. It only takes 30 minutes, and I just need to add a bag of spinach at the end. It's healthy and simple.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "Eating window is 12-8 pm",
          "memory_id": "a94b8527-dbe5-4741-80ce-ad7989edc620",
          "ground_truth_id": "mem_90",
          "score": 0.5545043355657819,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "7676e80e-02c3-4041-8911-c188e6b96d36",
          "ground_truth_id": "mem_90",
          "score": 0.43914495103778367,
          "metadata": {
            "ground_truth_id": "mem_90"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "f84bfca0-9dd5-4ae2-954d-fa6eb5574923",
          "ground_truth_id": "mem_117",
          "score": 0.43914495103778367,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": true
        },
        {
          "rank": 4,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "ac9d6312-7822-410b-91a8-73b311ebfe56",
          "ground_truth_id": "mem_117",
          "score": 0.43914495103778367,
          "metadata": {
            "ground_truth_id": "mem_117"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "MagSpeed scroll wheel",
          "memory_id": "6992f6b9-e0ec-4246-b3f6-cecaecdfaacc",
          "ground_truth_id": "mem_68",
          "score": 0.43914495103778367,
          "metadata": {
            "ground_truth_id": "mem_68"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_90",
        "mem_90",
        "mem_117",
        "mem_117",
        "mem_68"
      ],
      "found_position": 3,
      "hit": true
    },
    {
      "query_num": 99,
      "query": "What free services do I get with my library card?",
      "expected_id": "mem_118",
      "expected_memory": "The public library's website is amazing. I just found out I can use my library card to get free access to 'Kanopy' for streaming movies and 'LinkedIn Learning' for courses.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "volunteering",
          "memory_id": "3ce47810-dc5f-4207-b9d5-bb0211684048",
          "ground_truth_id": "mem_98",
          "score": 0.5454841528838849,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 2,
          "memory_text": "annual fee is $550",
          "memory_id": "60ec04c4-1f68-46cc-9d60-09d5ef42e426",
          "ground_truth_id": "mem_89",
          "score": 0.4946951711236445,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "signed up for Chase Sapphire Reserve",
          "memory_id": "c2681f32-c5f2-4a9e-9e96-fbd67e89a77f",
          "ground_truth_id": "mem_89",
          "score": 0.48547312878261467,
          "metadata": {
            "ground_truth_id": "mem_89"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "socialization",
          "memory_id": "121fd534-db94-481c-a49a-b7c0cc6c95a2",
          "ground_truth_id": "mem_98",
          "score": 0.45759602974064784,
          "metadata": {
            "ground_truth_id": "mem_98"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "courses",
          "memory_id": "5f098a6e-ae52-47cb-9017-e2396f124753",
          "ground_truth_id": "mem_118",
          "score": 0.43332167799148574,
          "metadata": {
            "ground_truth_id": "mem_118"
          },
          "is_correct": true
        }
      ],
      "retrieved_ids": [
        "mem_98",
        "mem_89",
        "mem_89",
        "mem_98",
        "mem_118"
      ],
      "found_position": 5,
      "hit": true
    },
    {
      "query_num": 100,
      "query": "Why am I annoyed with my neighbor?",
      "expected_id": "mem_119",
      "expected_memory": "My neighbor in apartment 3B, Tom, is always playing loud music, specifically techno, on weeknights around 11 PM. I need to remember to file a polite noise complaint with the building management.",
      "retrieved_memories": [
        {
          "rank": 1,
          "memory_text": "neighbor's name is Tom",
          "memory_id": "c4e48c49-4af9-4cf5-a9c8-07794c5f15e1",
          "ground_truth_id": "mem_119",
          "score": 0.6574841188178304,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": true
        },
        {
          "rank": 2,
          "memory_text": "Argument with partner",
          "memory_id": "eac0d503-53e0-4f6e-a1d3-0b6a52d3f9c0",
          "ground_truth_id": "mem_95",
          "score": 0.5595128951054251,
          "metadata": {
            "ground_truth_id": "mem_95"
          },
          "is_correct": false
        },
        {
          "rank": 3,
          "memory_text": "lives in apartment 3B",
          "memory_id": "d5b359fa-9512-4b0f-972f-7ae7a574bc7a",
          "ground_truth_id": "mem_119",
          "score": 0.5251105271513912,
          "metadata": {
            "ground_truth_id": "mem_119"
          },
          "is_correct": false
        },
        {
          "rank": 4,
          "memory_text": "landlord",
          "memory_id": "a01046fa-1f59-4ba5-aa73-ae3e11237e19",
          "ground_truth_id": "mem_112",
          "score": 0.47320711830218215,
          "metadata": {
            "ground_truth_id": "mem_112"
          },
          "is_correct": false
        },
        {
          "rank": 5,
          "memory_text": "allergic to Tide",
          "memory_id": "8ad7a386-d2ac-4c41-8a25-834b8a1092c0",
          "ground_truth_id": "mem_115",
          "score": 0.41080314997133593,
          "metadata": {
            "ground_truth_id": "mem_115"
          },
          "is_correct": false
        }
      ],
      "retrieved_ids": [
        "mem_119",
        "mem_95",
        "mem_119",
        "mem_112",
        "mem_115"
      ],
      "found_position": 1,
      "hit": true
    }
  ]
}